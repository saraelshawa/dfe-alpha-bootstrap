{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## notes for what the function should take\n",
    "bootstrap_number, default is 100\n",
    "\n",
    "\n",
    "network metric, either between centrality, connectivity\n",
    "\n",
    "\n",
    "top and bottom which percent (default 10%)\n",
    "\n",
    "current working directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import collections\n",
    "from numpy import random as rd\n",
    "from SFS import SFS\n",
    "import os\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove `0*': No such file or directory\n",
      "rm: cannot remove `bet*': No such file or directory\n",
      "rm: cannot remove `dfe_outfile_*': No such file or directory\n",
      "rm: cannot remove `output.txt': No such file or directory\n",
      "rm: cannot remove `prop_muts_in_s_ranges.out': No such file or directory\n",
      "rm: cannot remove `low_conn*': No such file or directory\n",
      "rm: cannot remove `alpha_omega_a_between_centrality.png': No such file or directory\n",
      "rm: cannot remove `random*': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "#deleting all to start a new bootstrap \n",
    "# !rm -r conn\n",
    "!rm -r run*\n",
    "!rm -r upper*\n",
    "!rm -r lower*\n",
    "!rm -r 0*\n",
    "!rm -r bet*\n",
    "!rm -r dfe_outfile_*\n",
    "!rm -r output.txt\n",
    "!rm -r prop_muts_in_s_ranges.out\n",
    "!rm -r low_conn*\n",
    "!rm -r alpha_omega_a_between_centrality.png\n",
    "!rm -r random*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"./runs\")\n",
    "for i in range(1,101):\n",
    "    os.mkdir(\"./runs/run\" + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dfe_outputs(filename, t, network_measure):\n",
    "    with open(filename) as f:\n",
    "        content = f.readlines()[0]\n",
    "        print(content)\n",
    "        match = re.search('lambda (\\d+.\\d+) selected_divergence (\\d+.\\d+) alpha (\\d+.\\d+) omega_A (\\d+.\\d+)', content)\n",
    "        print(\"this is match \" + str(match))\n",
    "        with open(t+\"_\" +network_measure+'_lambda.txt', 'a') as the_file:\n",
    "            the_file.write(\"{}\\n\".format(match.group(1)))\n",
    "            print(\"updated file: \" + str(the_file))\n",
    "        with open(t+\"_\" +network_measure+'_selected_divergence.txt', 'a') as the_file:\n",
    "            the_file.write(\"{}\\n\".format(match.group(2)))\n",
    "            print(\"updated file: \" + str(the_file))\n",
    "        with open(t+\"_\" +network_measure+'_alpha.txt', 'a') as the_file:\n",
    "            the_file.write(\"{}\\n\".format(match.group(3)))\n",
    "            print(\"updated file: \" + str(the_file))\n",
    "        with open(t+\"_\" +network_measure+'_omega_A.txt', 'a') as the_file:\n",
    "            the_file.write(\"{}\\n\".format(match.group(4)))\n",
    "            print(\"updated file: \" + str(the_file))\n",
    "        with open(t+\"_\" +network_measure+'_all.csv', 'a') as the_file:\n",
    "            the_file.write(\"{}\\t{}\\t{}\\t{}\\t \\n\".format(match.group(1), match.group(2), match.group(3), match.group(4)))\n",
    "            print(\"updated file: \" + str(the_file))\n",
    "#             df = pd.read_csv(t+\"_\" +network_measure+'_all.csv', header=None, delimiter=\"\\t\")\n",
    "#             print(\"here is the df \")\n",
    "#             print(df.head)\n",
    "#             df.rename(columns={0: 'lambda_'+ t, 1: 'selected_divergence_'+ t, 2:'alpha_' +t, 3:'omega_A_'+t}, inplace=True)\n",
    "#             df.to_csv(t+\"_\" +network_measure+'_all.csv', index=False)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "#             ##to add column names\n",
    "#             df = pd.read_csv(t+\"_\" +network_measure+'_all.csv', header=None, delimiter=\"\\t\")\n",
    "#             print(\"here is the df \")\n",
    "#             print(df.head)\n",
    "#             df.columns = ['lambda_'+ t, 'selected_divergence_'+ t, 'alpha_' +t, 'omega_A_'+t]\n",
    "#             df.to_csv(t+\"_\" +network_measure+'_all.csv')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'ness_ID', 'Cincerta_transcript_ID', 'PID',\n",
      "       'aligned_sites', 'k0', 'k4', 'diffs0', 'sites0', 'diffs4', 'sites4',\n",
      "       'gene', 'transcript', 'SFS0', 'SFS4', 'pi0', 'pi4', 'max_connectivity',\n",
      "       'BetweennessCentrality'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('connectivity_bc_irc1080_final_04-09-2020.csv', sep=\",\")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def sum_SFSs(list_of_SFSs):\n",
    "    # for a bunch of SFSs that are the same length sum them alllll up into one big one\\\n",
    "#     sfs_size = len(list_of_SFSs[0])\n",
    "#     for i in range(sfs_size):\n",
    "#         sum([sfs[i] for sfs in list_of_SFSs ]\n",
    "    total_SFS = [sum(i) for i in zip(*list_of_SFSs)]\n",
    "    return total_SFS\n",
    "\n",
    "def column2SFSs(column_of_SFSs):\n",
    "    list_of_SFSs = []\n",
    "    for s in list(column_of_SFSs):\n",
    "        exec(\"list_of_SFSs.append(\" + s + \")\")\n",
    "    return list_of_SFSs\n",
    "\n",
    "def make_dfe_inputs(lower_path, upper_path):\n",
    "    df = pd.read_csv('connectivity_bc_irc1080_final_04-09-2020.csv', sep=\",\")\n",
    "    \n",
    "    x = \"BetweennessCentrality\"\n",
    "    gene_name = \"gene\"\n",
    "    cutoff_percent  = 0.10\n",
    "    percentage = \"10\"\n",
    "    number_genes = df.shape[0]\n",
    "    cutoff_number = round(number_genes*cutoff_percent)\n",
    "    cutoff_high  = sorted(list(df[x]))[number_genes-cutoff_number]\n",
    "    cutoff_low = sorted(list(df[x]))[cutoff_number]\n",
    "\n",
    "    df_low = df[df[x] <= cutoff_low]\n",
    "    df_high = df[df[x] >= cutoff_high]\n",
    "    \n",
    "\n",
    "    df_low_names = df_low[gene_name].tolist()\n",
    "    random_low_lst = (list(rd.choice(df_low_names, size=100, replace=True)))  # cleaned = df[df['genename'].isin(keep_lst)] #ignores duplicates so this is wrong \n",
    "    low_newDF = pd.DataFrame() #creates a new dataframe that's empty\n",
    "    for key,value in (dict(Counter(random_low_lst)).items()):\n",
    "        for i in range(value):\n",
    "                low_newDF = low_newDF.append(df_low.loc[df_low[gene_name] == key]) # ignoring index is optional\n",
    "\n",
    "                \n",
    "    df_high_names = df_high[gene_name].tolist()\n",
    "    random_high_lst = (list(rd.choice(df_high_names, size=100, replace=True)))\n",
    "    high_newDF = pd.DataFrame() #creates a new dataframe that's empty\n",
    "    for key,value in (dict(Counter(random_high_lst)).items()):\n",
    "        for i in range(value):\n",
    "                high_newDF = high_newDF.append(df_high.loc[df_high[gene_name] == key]) # ignoring index is optional\n",
    "        \n",
    "\n",
    "    total_SFS0_low = SFS(sum_SFSs(column2SFSs(low_newDF.SFS0)))\n",
    "    total_SFS4_low = SFS(sum_SFSs(column2SFSs(low_newDF.SFS4)))\n",
    "    total_SFS0_high = SFS(sum_SFSs(column2SFSs(high_newDF.SFS0)))\n",
    "    total_SFS4_high= SFS(sum_SFSs(column2SFSs(high_newDF.SFS4)))\n",
    "\n",
    "    SFSs = [total_SFS0_low,total_SFS4_low,total_SFS0_high,total_SFS4_high]\n",
    "    \n",
    "    for s in SFSs:\n",
    "        s.fold()\n",
    "\n",
    "    sfs_lower_network_measure = \"SFS.lower\" + str(percentage) + \"th_\" + str(network_measure) + \".txt\"\n",
    "    SFS_lower_0 = \" \".join(str(item) for item in SFSs[0].sfs)\n",
    "    SFS_lower_1 = \" \".join(str(item) for item in SFSs[1].sfs)\n",
    "    !printf \"1\\n18\\n\" > $lower_path/$sfs_lower_network_measure\n",
    "    !echo $SFS_lower_0 >> $lower_path/$sfs_lower_network_measure\n",
    "    !echo $SFS_lower_1 >> $lower_path/$sfs_lower_network_measure\n",
    "    \n",
    "    \n",
    "    sfs_upper_network_measure = \"SFS.upper\" + str(percentage) + \"th_\" + str(network_measure) + \".txt\"\n",
    "    SFS_upper_0 = \" \".join(str(item) for item in SFSs[2].sfs)\n",
    "    SFS_upper_1 = \" \".join(str(item) for item in SFSs[3].sfs)\n",
    "    !printf \"1\\n18\\n\" > $upper_path/$sfs_upper_network_measure\n",
    "    !echo $SFS_upper_0 >> $upper_path/$sfs_upper_network_measure\n",
    "    !echo $SFS_upper_1 >> $upper_path/$sfs_upper_network_measure\n",
    "    \n",
    "    divergence_lower_network_measure = \"divergence.lower\" +str(percentage) + \"th_\" + str(network_measure) + \".txt\"\n",
    "    low_sites_0 = sum(low_newDF.sites0)\n",
    "    low_diff_0 = sum(low_newDF.diffs0)\n",
    "    low_sites_4 = sum(low_newDF.sites4)\n",
    "    low_diff_4 = sum(low_newDF.diffs4)\n",
    "    !echo 1 $low_sites_0 $low_diff_0 > $lower_path/$divergence_lower_network_measure\n",
    "    !echo 0 $low_sites_4 $low_diff_4 >> $lower_path/$divergence_lower_network_measure\n",
    "\n",
    "    divergence_upper_network_measure = \"divergence.upper\" + str(percentage) + \"th_\" + str(network_measure) + \".txt\"\n",
    "    high_sites_0 = sum(high_newDF.sites0)\n",
    "    high_diff_0 = sum(high_newDF.diffs0)\n",
    "    high_sites_4 = sum(high_newDF.sites4)\n",
    "    high_diff_4 = sum(high_newDF.diffs4)\n",
    "    !echo 1 $high_sites_0 $high_diff_0 > $upper_path/$divergence_upper_network_measure\n",
    "    !echo 0 $high_sites_4 $high_diff_4 >> $upper_path/$divergence_upper_network_measure\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\selsh\\repos\\Network-Evolution\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\selsh\\repos\\Network-Evolution\\runs\n",
      "this is the path C:\\Users\\selsh\\repos\\Network-Evolution\\runs\\run1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'printf' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'printf' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\selsh\\repos\\Network-Evolution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dfe_first_step.sh: line 4: /scratch/research/tmp_apps/dfe-alpha-release-2.16/est_dfe: No such file or directory\n",
      "dfe_first_step.sh: line 4: /scratch/research/tmp_apps/dfe-alpha-release-2.16/est_dfe: No such file or directory\n",
      "dfe_first_step.sh: line 4: /scratch/research/tmp_apps/dfe-alpha-release-2.16/est_dfe: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with first step dfe\n",
      "++++++++++++++++++++++++++++++++++++++*******1*********************************************************************************\n",
      "second step is prop_muts_in_s_ranges -c $1 -o $2\n",
      "C:\\Users\\selsh\\repos\\Network-Evolution\\runs/run1/upper10th/upper10th_irc1080_betweenness_centrality_selected/est_dfe.out\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dfe_first_step.sh: line 4: /scratch/research/tmp_apps/dfe-alpha-release-2.16/est_dfe: No such file or directory\n",
      "dfe_second_step.sh: line 4: /scratch/research/tmp_apps/dfe-alpha-release-2.16/prop_muts_in_s_ranges: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done second step\n",
      "------------------------------------------------**************-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dfe_second_step.sh: line 4: /scratch/research/tmp_apps/dfe-alpha-release-2.16/prop_muts_in_s_ranges: No such file or directory\n",
      "testing.sh: line 4: /scratch/research/tmp_apps/dfe-alpha-release-2.16/est_alpha_omega: No such file or directory\n",
      "testing.sh: line 4: /scratch/research/tmp_apps/dfe-alpha-release-2.16/est_alpha_omega: No such file or directory\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\selsh\\\\repos\\\\Network-Evolution\\\\runs/run1/upper10th/est_alpha_omega.out'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-ae351ddc8414>\u001b[0m in \u001b[0;36mget_dfe_outputs\u001b[1;34m(filename, t, network_measure)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_dfe_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnetwork_measure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m         \u001b[0mcontent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mmatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'lambda (\\d+.\\d+) selected_divergence (\\d+.\\d+) alpha (\\d+.\\d+) omega_A (\\d+.\\d+)'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\selsh\\\\repos\\\\Network-Evolution\\\\runs/run1/upper10th/est_alpha_omega.out'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import os\n",
    "network_measure = \"irc1080_betweenness_centrality\"\n",
    "# rootdir = \"/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs\" \n",
    "# rootdir_runs = \"/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs\" \n",
    "rootdir = r\"C:\\Users\\selsh\\repos\\Network-Evolution\\runs\"\n",
    "rootdir_runs = r\"C:\\Users\\selsh\\repos\\Network-Evolution\\runs\"\n",
    "# rootdir_org = \"/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/\"\n",
    "rootdir_org = r\"C:\\Users\\selsh\\repos\\Network-Evolution\"\n",
    "print(rootdir)\n",
    "i = 0\n",
    "upper = \"upper10th\"\n",
    "lower = \"lower10th\"\n",
    "# network_measure = \"chlamynet_betweenness_centr\"\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    for folder in dirs:\n",
    "        if folder.startswith(\"r\"):\n",
    "            new_path = os.path.join(subdir, folder)\n",
    "            print(\"this is the path \" + str(new_path))\n",
    "            os.chdir(new_path) #change directory to new_path \n",
    "            if not os.path.exists(upper) and not os.path.exists(lower):\n",
    "                os.makedirs(upper)\n",
    "                os.makedirs(lower)\n",
    "                \n",
    "            #make folders in lower folder for each bootstrap   \n",
    "            os.chdir(new_path + \"/\" + lower) #change directory to new_path\n",
    "            if not os.path.exists(lower + \"_\" + network_measure + \"_neutral\") and not os.path.exists(lower + \"_\" + network_measure + \"_selected\"):\n",
    "                os.makedirs(lower + \"_\" + network_measure + \"_neutral\")\n",
    "                os.makedirs(lower + \"_\" + network_measure + \"_selected\")\n",
    "            \n",
    "            os.chdir(new_path + \"/\" + upper) #change directory to new_path\n",
    "            \n",
    "            if not os.path.exists(upper + \"_\" + network_measure + \"_neutral\") and not os.path.exists(upper + \"_\" + network_measure + \"_selected\"):\n",
    "                os.makedirs(upper + \"_\" + network_measure + \"_neutral\")\n",
    "                os.makedirs(upper + \"_\" + network_measure + \"_selected\")\n",
    "\n",
    "\n",
    "\n",
    "#             send the two paths (upper10th and lower10th to the function, to enter divergence and diversity )\n",
    "            os.chdir(rootdir_org)\n",
    "            make_dfe_inputs(new_path + \"/\" + lower, new_path + \"/\" + upper)\n",
    "            \n",
    "            data_path_1 = \"/scratch/research/tmp_apps/dfe-alpha-release-2.16/data/\"\n",
    "            runs_folder = rootdir_runs\n",
    "#             runs_folder = \"/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs\"\n",
    "            print(os.getcwd())\n",
    "            \n",
    "            \n",
    "            ############ class 0 lower and upper, NEUTRAL          \n",
    "            class0_config_lower_filename = '{}/{}/{}/run.{}.est_dfe-site_class0.config.txt'.format(runs_folder, folder, lower, lower)\n",
    "            f = open(class0_config_lower_filename, 'w')\n",
    "            f.write(\"data_path_1\\t{} \\nsfs_input_file \\t    {}/{}/{}/SFS.{}_{}.txt \\nest_dfe_results_dir \\t   {}/{}/{}/{}_{}_neutral \\nsite_class 0 \\nfold       1 \\nepochs     2 \\nsearch_n2       1 \\nt2_variable     1 \\nt2              50\".format(data_path_1, runs_folder, folder, lower, lower, network_measure, runs_folder, folder, lower, lower, network_measure))\n",
    "            f.close()\n",
    "            \n",
    "            #outputs info in neutral folder in lower (neut_exp_obs_allele_freqs.csv)\n",
    "            !bash dfe_first_step.sh $class0_config_lower_filename\n",
    "            \n",
    "            #do the same for upper: \n",
    "            class0_config_upper_filename = '{}/{}/{}/run.{}.est_dfe-site_class0.config.txt'.format(runs_folder, folder, upper, upper)\n",
    "            f = open(class0_config_upper_filename, 'w')\n",
    "            f.write(\"data_path_1\\t{} \\nsfs_input_file \\t    {}/{}/{}/SFS.{}_{}.txt \\nest_dfe_results_dir \\t   {}/{}/{}/{}_{}_neutral \\nsite_class 0 \\nfold       1 \\nepochs     2 \\nsearch_n2       1 \\nt2_variable     1 \\nt2              50\".format(data_path_1, runs_folder, folder, upper, upper, network_measure, runs_folder, folder, upper, upper, network_measure))\n",
    "            f.close()\n",
    "            \n",
    "            #outputs info in neutral folder in upper (neut_exp_obs_allele_freqs.csv)\n",
    "            !bash dfe_first_step.sh $class0_config_upper_filename\n",
    "            \n",
    "            \n",
    "            ###########class 1 lower and upper, SELECTED\n",
    "            \n",
    "            ### lower and selected \n",
    "            #demographic folder is neutral NOT selected \n",
    "    \n",
    "            class1_config_lower_filename = '{}/{}/{}/run.{}.est_dfe-site_class1.config.txt'.format(runs_folder, folder, lower, lower)\n",
    "            f = open(class1_config_lower_filename, 'w')\n",
    "            f.write(\"data_path_1\\t{} \\nsfs_input_file \\t    {}/{}/{}/SFS.{}_{}.txt \\nest_dfe_results_dir \\t   {}/{}/{}/{}_{}_selected \\n \\nest_dfe_demography_results_file    {}/{}/{}/{}_{}_neutral/est_dfe.out \\n site_class    1 \\nfold    1 \\nepochs    2 \\nmean_s_variable    1 \\nmean_s    -0.1 \\nbeta_variable    1 \\nbeta    0.5\".format(data_path_1, runs_folder, folder, lower, lower, network_measure, runs_folder, folder, lower, lower, network_measure, runs_folder, folder, lower, lower, network_measure))\n",
    "            f.close()\n",
    "\n",
    "            #outputs sel_exp_obs_allele_freqs.csv in selected \n",
    "            !bash dfe_first_step.sh $class1_config_lower_filename\n",
    "            \n",
    "\n",
    "            class1_config_upper_filename = '{}/{}/{}/run.{}.est_dfe-site_class1.config.txt'.format(runs_folder, folder, upper, upper)\n",
    "            f = open(class1_config_upper_filename, 'w')\n",
    "            f.write(\"data_path_1\\t{} \\nsfs_input_file \\t    {}/{}/{}/SFS.{}_{}.txt \\nest_dfe_results_dir \\t   {}/{}/{}/{}_{}_selected \\n \\nest_dfe_demography_results_file    {}/{}/{}/{}_{}_neutral/est_dfe.out \\n site_class    1 \\nfold    1 \\nepochs    2 \\nmean_s_variable    1 \\nmean_s    -0.1 \\nbeta_variable    1 \\nbeta    0.5\".format(data_path_1, runs_folder, folder, upper, upper, network_measure, runs_folder, folder, upper, upper, network_measure, runs_folder, folder, upper, upper, network_measure))\n",
    "            f.close()\n",
    "\n",
    "            #outputs sel_exp_obs_allele_freqs.csv in selected \n",
    "            !bash dfe_first_step.sh $class1_config_upper_filename\n",
    "            print(\"done with first step dfe\")\n",
    "            \n",
    "            #################################################step 1 of dfe is done     \n",
    "            i+= 1\n",
    "            print(\"++++++++++++++++++++++++++++++++++++++*******\" + str(i) + \"*********************************************************************************\" )\n",
    "\n",
    "            print(\"second step is prop_muts_in_s_ranges -c $1 -o $2\")\n",
    "\n",
    "            ##upper DFE results\n",
    "            upper_estdfe_filename = '{}/{}/{}/{}_{}_selected/est_dfe.out'.format(runs_folder, folder, upper, upper, network_measure)\n",
    "            print(upper_estdfe_filename)\n",
    "            !bash dfe_second_step.sh $upper_estdfe_filename $runs_folder/$folder/upperDFE.results.txt\n",
    "            \n",
    "            lower_estdfe_filename = '{}/{}/{}/{}_{}_selected/est_dfe.out'.format(runs_folder, folder, lower, lower, network_measure)\n",
    "            \n",
    "            !bash dfe_second_step.sh $lower_estdfe_filename ./runs/$folder/lowerDFE.results.txt\n",
    "            print(\"done second step\")\n",
    " \n",
    "            print(\"------------------------------------------------**************-------------------------\")\n",
    "    \n",
    "    \n",
    "            ##for lower \n",
    "            alpha_omega_config_lower_file = '{}/{}/{}/run.{}.est_alpha_omega.config.txt'.format(runs_folder, folder, lower, lower)\n",
    "            f = open(alpha_omega_config_lower_file, 'w')\n",
    "            f.write(\"data_path_1\\t{} \\ndivergence_file \\t {}/{}/{}/divergence.{}_{}.txt \\nest_alpha_omega_results_file \\t {}/{}/{}/est_alpha_omega.out \\nest_dfe_results_file \\t {}/{}/{}/{}_{}_selected/est_dfe.out \\nneut_egf_file \\t {}/{}/{}/{}_{}_neutral/neut_egf.out \\nsel_egf_file \\t {}/{}/{}/{}_{}_selected/sel_egf.out \\ndo_jukes_cantor\\t 1 \\nremove_poly\\t 1\".format(data_path_1,runs_folder, folder, lower, lower, network_measure, runs_folder, folder, lower, runs_folder, folder, lower, lower, network_measure, runs_folder, folder, lower, lower, network_measure, runs_folder, folder, lower, lower, network_measure))\n",
    "            f.close()\n",
    "            \n",
    "            !bash testing.sh $alpha_omega_config_lower_file\n",
    "\n",
    "            ##for upper \n",
    "            alpha_omega_config_upper_file = '{}/{}/{}/run.{}.est_alpha_omega.config.txt'.format(runs_folder, folder, upper, upper)\n",
    "            f = open(alpha_omega_config_upper_file, 'w')\n",
    "            f.write(\"data_path_1\\t{} \\ndivergence_file \\t {}/{}/{}/divergence.{}_{}.txt \\nest_alpha_omega_results_file \\t {}/{}/{}/est_alpha_omega.out \\nest_dfe_results_file \\t {}/{}/{}/{}_{}_selected/est_dfe.out \\nneut_egf_file \\t {}/{}/{}/{}_{}_neutral/neut_egf.out \\nsel_egf_file \\t {}/{}/{}/{}_{}_selected/sel_egf.out \\ndo_jukes_cantor\\t 1 \\nremove_poly\\t 1\".format(data_path_1,runs_folder, folder, upper, upper, network_measure, runs_folder, folder, upper, runs_folder, folder, upper, upper, network_measure, runs_folder, folder, upper, upper, network_measure, runs_folder, folder, upper, upper, network_measure))\n",
    "            f.close()\n",
    "            \n",
    "            !bash testing.sh $alpha_omega_config_upper_file\n",
    "            \n",
    "            get_dfe_outputs('{}/{}/{}/est_alpha_omega.out'.format(runs_folder, folder, upper), upper, network_measure)\n",
    "            get_dfe_outputs('{}/{}/{}/est_alpha_omega.out'.format(runs_folder, folder, lower), lower, network_measure)\n",
    "#             get_dfe_outputs('/scratch/research/projects/chlamydomonas/network_evolution/analysis/dfe/bootstrap/' + folder + '/upper10th/est_alpha_omega.out', \"upper\")\n",
    "#             get_dfe_outputs('/scratch/research/projects/chlamydomonas/network_evolution/analysis/dfe/bootstrap/' + folder + '/lower10th/est_alpha_omega.out', \"lower\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# getting prop_muts_in_s_ranges all in one file for upper and for lower "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run84\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run56\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run7\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run82\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run24\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run50\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run43\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run10\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run2\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run53\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run90\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run15\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run31\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run54\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run26\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run41\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run34\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run87\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run14\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run4\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run62\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run58\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run61\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run97\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run32\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run100\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run91\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run33\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run39\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run76\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run18\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run74\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run17\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run48\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run79\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run30\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run69\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run80\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run29\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run44\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run25\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run60\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run8\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run45\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run88\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run93\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run64\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run78\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run36\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run99\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run5\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run70\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run19\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run1\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run47\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run23\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run42\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run65\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run92\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run72\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run52\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run71\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run73\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run27\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run94\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run35\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run77\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run96\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run9\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run66\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run20\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run55\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run81\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run13\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run51\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run86\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run38\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run59\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run40\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run28\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run83\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run63\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run98\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run67\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run22\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run46\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run3\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run68\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run49\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run37\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run89\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run21\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run12\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run57\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run85\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run95\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run16\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run11\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run6\n",
      "/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs/run75\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "network_measure = \"irc1080_betweenness_centrality\"\n",
    "upper = \"upper10th\"\n",
    "lower = \"lower10th\"\n",
    "\n",
    "# def get_dfe_outputs(filename, t):\n",
    "#     with open(filename) as f:\n",
    "#         content = f.readlines()[0]\n",
    "#         return content\n",
    "\n",
    "rootdir = \"/scratch/research/projects/chlamydomonas/network_evolution/analysis/August2020_Sara/bootstrap/runs\" \n",
    "print(rootdir)\n",
    "i = 0\n",
    "file_out_lower = open(\"dfe_outfile_\" + str(lower) +\"_\" + str(network_measure) + '.csv', 'w')\n",
    "file_out_upper = open(\"dfe_outfile_\" + str(upper) +\"_\" + str(network_measure) + '.csv', 'w')\n",
    "import os\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    for folder in dirs:\n",
    "        if folder.startswith(\"r\"):\n",
    "            new_path = os.path.join(subdir, folder)\n",
    "            print(new_path)\n",
    "            with open(new_path + \"/lowerDFE.results.txt\") as f1:\n",
    "                file_out_lower.write(f1.readlines()[0])\n",
    "            with open(new_path + \"/upperDFE.results.txt\") as f2:\n",
    "                file_out_upper.write(f2.readlines()[0])\n",
    "file_out_lower.close()\n",
    "file_out_upper.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_dfe_outputs(filename, t, network_measure):\n",
    "#     with open(filename) as f:\n",
    "#         content = f.readlines()[0]\n",
    "#         print(content)\n",
    "#         match = re.search('lambda (\\d+.\\d+) selected_divergence (\\d+.\\d+) alpha (\\d+.\\d+) omega_A (\\d+.\\d+)', content)\n",
    "#         print(\"this is match \" + str(match))\n",
    "#         with open(t+\"_\" +network_measure+'_lambda.txt', 'a') as the_file:\n",
    "#             the_file.write(\"{}\\n\".format(match.group(1)))\n",
    "#             print(\"updated file: \" + str(the_file))\n",
    "#         with open(t+\"_\" +network_measure+'_selected_divergence.txt', 'a') as the_file:\n",
    "#             the_file.write(\"{}\\n\".format(match.group(2)))\n",
    "#             print(\"updated file: \" + str(the_file))\n",
    "#         with open(t+\"_\" +network_measure+'_alpha.txt', 'a') as the_file:\n",
    "#             the_file.write(\"{}\\n\".format(match.group(3)))\n",
    "#             print(\"updated file: \" + str(the_file))\n",
    "#         with open(t+\"_\" +network_measure+'_omega_A.txt', 'a') as the_file:\n",
    "#             the_file.write(\"{}\\n\".format(match.group(4)))\n",
    "#             print(\"updated file: \" + str(the_file))\n",
    "#         with open(t+\"_\" +network_measure+'_all.csv', 'a') as the_file:\n",
    "#             the_file.write(\"{},{},{},{}\\n\".format(match.group(1), match.group(2), match.group(3), match.group(4)))\n",
    "#             print(\"updated file: \" + str(the_file))\n",
    "#             ##to add column names\n",
    "#             df = pd.read_csv(t+\"_\" +network_measure+'_all.csv', header=None)\n",
    "#             df.columns = ['lambda_'+ t, 'selected_divergence_'+ t, 'alpha_' +t, 'omega_A_'+t]\n",
    "#             df.to_csv(t+\"_\" +network_measure+'_all.csv')\n",
    "            \n",
    "# import pandas as pd\n",
    "# t = \"lower10th\"\n",
    "# df = pd.read_csv(\"lower10th_irc1080_betweenness_centrality_all.csv\", header=None)\n",
    "# df.columns = ['lambda_'+ t, 'selected_divergence_'+ t, 'alpha_' +t, 'omega_A_'+t]\n",
    "# df.to_csv(\"lower10th_irc1080_betweenness_centrality_all.csv\")\n",
    "\n",
    "# t = \"upper10th\"\n",
    "# df = pd.read_csv(\"upper10th_irc1080_betweenness_centrality_all.csv\", header=None)\n",
    "# df.columns = ['lambda_'+ t, 'selected_divergence_'+ t, 'alpha_' +t, 'omega_A_'+t]\n",
    "# df.to_csv(\"upper10th_irc1080_betweenness_centrality_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda 4.6 selected_divergence 23.4 alpha 2.4 omega_A 4.5\n",
      "\n",
      "this is match <_sre.SRE_Match object; span=(0, 57), match='lambda 4.6 selected_divergence 23.4 alpha 2.4 ome>\n",
      "updated file: <_io.TextIOWrapper name='lower_bc_all.csv' mode='a' encoding='UTF-8'>\n"
     ]
    },
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 3, saw 5\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-c45a5e1b66bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test_with_col.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mget_dfe_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"untitled.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lower\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"bc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-41-c45a5e1b66bd>\u001b[0m in \u001b[0;36mget_dfe_outputs\u001b[0;34m(filename, t, network_measure)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mthe_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;31m##to add column names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_\"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mnetwork_measure\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_all.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"here is the df \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nrows'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1993\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1994\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1995\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1996\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 3, saw 5\n"
     ]
    }
   ],
   "source": [
    "# def get_dfe_outputs(filename, t, network_measure):\n",
    "#     with open(filename) as f:\n",
    "#         content = f.readlines()[0]\n",
    "#         print(content)\n",
    "#         match = re.search('lambda (\\d+.\\d+) selected_divergence (\\d+.\\d+) alpha (\\d+.\\d+) omega_A (\\d+.\\d+)', content)\n",
    "#         print(\"this is match \" + str(match))\n",
    "#         with open(t+\"_\" +network_measure+'_all.csv', 'a') as the_file:\n",
    "#             the_file.write(\"{},{},{},{}\\n\".format(match.group(1), match.group(2), match.group(3), match.group(4)))\n",
    "#             print(\"updated file: \" + str(the_file))\n",
    "#             the_file.close\n",
    "#             ##to add column names\n",
    "#             df = pd.read_csv(t+\"_\" +network_measure+'_all.csv', header=None, delimiter=\",\")\n",
    "#             print(\"here is the df \")\n",
    "#             print(df.head)\n",
    "#             df.rename(columns={0: 'lambda_'+ t, 1: 'selected_divergence_'+ t, 2:'alpha_' +t, 3:'omega_A_'+t}, inplace=True)\n",
    "#             df.to_csv('test_with_col.csv', index=False)\n",
    "            \n",
    "# get_dfe_outputs(\"untitled.txt\", \"lower\", \"bc\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
